---
{"dg-publish":true,"permalink":"/topics/machine-learning/machine-learning/","dgHomeLink":true,"dgPassFrontmatter":false}
---


### Why theory is useful/important ?
> Is it important to practioners/enthusiasts ?
> How to find motivationâ€¦ ?
- to get the "basic" language (conceptual knowledge) to be able to read **ML research papers** (even if just with a "broad understanding", and not in depthâ€¦)
- it is a **complementary** aspect (with practice) for a career in data
	- but very important for **Data scientist** or **ML scientist/researcher** (or to *at least understand them* a bit at workâ€¦)
	- to have a **wider view** and improve (practice?) skills => beneficial in the long run to use/compose with those theoretical "tools"
	- their is **no** theory-practice **fence**, find a balance between both "sides"
- to understand thoroughly (one should have a solid background in math.) or even more to **design/invent/create new toolsâ€¦** after getting a more profound knowledge (it takes time)
	- even if, as only a simple "user" of the algorithm at the moment, it's less relevantâ€¦ (?)
		- but important **to not make "silly" mistakes** and **be more confident**, and also to know in which situations a method is more applicable (tough question?)
- (Less likely?) some of the practical part of ML **could/will be (gradually?) automated one day**â€¦ (AutoML?) => learn the theory/math. to stay relevant/"ahead", more ready to adapt and able to work and persevere on tough/advanced subjects or other fieldsâ€¦ (=> It doesn't suffice anymore to "just" know how (and when) to use things from a toolbox â€¦)
- to know the mathematical frameworks on which is based ML/AI/DL/RL/â€¦ sounds cool and ==more satisfactory== than applying/calling sklearn/stats functions mindlessly (as black-boxes). **To intelligently work with concepts of practical importance** (overfitting, â€¦)
	- Statistical learning theory, Bayesian inference, Hypothesis testing, correlation vs causality, â€¦
		- Even if "*recent improvements in ML : dropout, residual connections, dense connections, batch normalization, aren't rooted in particularly deep theory*"
	- some of them are "far from perfect" (?) so we must **know their limitations** or assumptions
- extrinsic motivation : to have a degree, money, â€¦
- (irrelevant) it's fun to learn, life-long, and "sharpen its knife" with self-education and applications : to show off your skills

=> [Why is it so important to have principled and mathematical theories for ML ?](https://stats.stackexchange.com/questions/318463/why-is-it-so-important-to-have-principled-and-mathematical-theories-for-machine)

---
### Toggl recent activity
```toggl
summary PAST 3 DAYS
include projects "AI/ML/DL/RL", "Algorithms", "Technical reading", "Maths", "MOOC", "Python", "Tehnical reading"
SORT DESC
```
```toggl
LIST PAST 5 DAYS
INCLUDE projects "AI/ML/DL/RL", "Algorithms", "Technical reading", "Maths", "MOOC", "Python"
SORT DESC
```

---
### Current topics
| File                                                                                                                       | category              | progress                                  | difficulty | tags                                           | wip  |
| -------------------------------------------------------------------------------------------------------------------------- | --------------------- | ----------------------------------------- | ---------- | ---------------------------------------------- | ---- |
| [[Topics/Mathematics/Statistics and probabilities/Statistics/Spearman's rank correlation.md\|Spearman's rank correlation]] | Stats, correlation    | ![progress](https://progress-bar.dev/70/) | ðŸŸ¢         | <ul><li>#statistics</li></ul>                  | \-   |
| [[Topics/Machine Learning/Models/Logistic regression.md\|Logistic regression]]                                             | Machine learning      | ![progress](https://progress-bar.dev/50/) | ðŸŸ¡         | <ul></ul>                                      | \-   |
| [[Topics/Mathematics/Statistics and probabilities/Statistics/Hypothesis testing.md\|Hypothesis testing]]                   | Stats                 | ![progress](https://progress-bar.dev/33/) | ðŸŸ          | <ul><li>#statistics</li></ul>                  | \-   |
| [[Topics/Machine Learning/Models/Gated Recurrent Unit (paper, 2014).md\|Gated Recurrent Unit (paper, 2014)]]               | RNN, NLP              | ![progress](https://progress-bar.dev/33/) | ðŸŸ          | <ul></ul>                                      | \-   |
| [[___INBOX___/__Ã  trier/Kernel density estimation.md\|Kernel density estimation]]                                          | Maths                 | ![progress](https://progress-bar.dev/25/) | ðŸŸ          | <ul></ul>                                      | \-   |
| [[___INBOX___/__Ã  trier/QDA.md\|QDA]]                                                                                      | \-                    | ![progress](https://progress-bar.dev/20/) | ðŸŸ¡         | <ul></ul>                                      | \-   |
| [[___INBOX___/__Ã  trier/Expectation-maximization algorithm.md\|Expectation-maximization algorithm]]                        | Maths                 | ![progress](https://progress-bar.dev/15/) | ðŸ”´         | <ul></ul>                                      | true |
| [[___INBOX___/__Ã  trier/Bayes error rate.md\|Bayes error rate]]                                                            | \-                    | ![progress](https://progress-bar.dev/15/) | ðŸŸ¡         | <ul></ul>                                      | \-   |
| [[Topics/Mathematics/QR decomposition.md\|QR decomposition]]                                                               | Linear algebra        | ![progress](https://progress-bar.dev/15/) | ðŸŸ          | <ul></ul>                                      | true |
| [[Topics/Machine Learning/Models/Transformer (paper, 2017).md\|Transformer (paper, 2017)]]                                 | NLP, Attention models | ![progress](https://progress-bar.dev/15/) | ðŸ”´         | <ul></ul>                                      | \-   |
| [[Topics/Machine Learning/Research Papers/AlphaCode (2022).md\|AlphaCode (2022)]]                                          | \-                    | ![progress](https://progress-bar.dev/15/) | ðŸ”´         | <ul></ul>                                      | \-   |
| [[Topics/Mathematics/Statistics and probabilities/Generalized linear models.md\|Generalized linear models]]                | \-                    | ![progress](https://progress-bar.dev/10/) | ðŸŸ          | <ul><li>#ml/MSG/todo</li><li>#ml/MSG</li></ul> | true |
| [[Topics/Machine Learning/Models/CLIP (2021).md\|CLIP (2021)]]                                                             | \-                    | ![progress](https://progress-bar.dev/1/)  | ðŸ”´         | <ul></ul>                                      | \-   |
| [[___INBOX___/__Ã  trier/LARS (2004).md\|LARS (2004)]]                                                                      | \-                    | ![progress](https://progress-bar.dev/\-/) | \-         | <ul></ul>                                      | \-   |


---
### News/websites
- https://lastweekin.ai/

### Concepts
- Bayesian learning : [[Topics/Mathematics/Statistics and probabilities/Bayesian inference, analysis ...|Bayesian inference, analysis ...]]

### Models
- [[___INBOX___/__Ã  trier/Linear Models|Linear Models]] (Ridge Regression, LASSO, ElasticNet, ...)
- [[Topics/Machine Learning/Models/Logistic regression|Logistic regression]] for classification
- [[Topics/Machine Learning/Models/Support Vector Machine (1992)|Support Vector Machine (1992)]]
- [[Topics/Machine Learning/Models/Random Forest (1995)|Random Forest (1995)]]
- [[Topics/Machine Learning/Models/Probabilistic Graphical Models|Probabilistic Graphical Models]]

### Books

<div class="transclusion internal-embed is-loaded"><div class="markdown-embed">

<div class="markdown-embed-title">



</div>



- [[Topics/Machine Learning/Books/The Elements of Statistical Learning (2009, 2016)|The Elements of Statistical Learning (2009, 2016)]]
- [[Topics/Machine Learning/Books/An Introduction to Statistical Learning/An Introduction to Statistical Learning (2013, 2021)|An Introduction to Statistical Learning (2013, 2021)]]
- [[Topics/Machine Learning/Books/Hands-on ML with scikit-learn, Keras, and Tensorflow 2 (2017, 2019)|Hands-on ML with scikit-learn, Keras, and Tensorflow 2 (2017, 2019)]]
- [[Topics/Machine Learning/Books/Pattern Recognition and Machine Learning (2006)|Pattern Recognition and Machine Learning (2006)]]


### See also
- [[___INBOX___/__Ã  trier/Books on Data Science|Books on Data Science]]
- [[Topics/Mathematics/Books on Statistics|Books on Statistics]]


</div></div>


### Tasks
- [[___INBOX___/__Ã  trier/Binary classification|Binary classification]]
	- eg. [[Topics/Machine Learning/Concepts/Sentiment analysis|Sentiment analysis]]
