---
{"dg-publish":true,"dg-permalink":"PCA","permalink":"/PCA/"}
---

- Principal Component Analysis
- Invented by [[Topics/Mathematics/People/Karl Pearson|Karl Pearson]] in **1901**, then later independently developed and "named" by [[Topics/Mathematics/People/Harold Hotelling|Harold Hotelling]], **1933**
- useful **linear** transformation technique -> ?
	- like [[Topics/Mathematics/LDA|LDA]]
- PCA ignores "class" labels, it finds the directions that maximize [[Topics/Mathematics/Statistics and probabilities/Variance|variance]]
- Projection in a small subspace

---
-  by [[Topics/Machine Learning/People/Sebastian Raschka|Sebastian Raschka]] -> [PCA in 3 steps](https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html) (2015)
	- in 3 steps
		- Eigendecomposition of the covariance matrix
			- or Singular Value Decomposition (SVD) **to improve the computational efficiency**
		- Selection Principal Components
		- Projection onto the new feature space


### TODO
- [ ] Reread and code Raschka's tutorial
- [ ] Do classification on PCA -> iris dataset, ...etc (?)

---
[PCA > History (wikipedia)](https://en.wikipedia.org/wiki/Principal_component_analysis#History)

